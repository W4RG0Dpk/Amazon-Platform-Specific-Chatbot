{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4afa1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: imports & configuration\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import subprocess\n",
    "import uuid\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import faiss\n",
    "import pickle\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util  # util for cos_sim in evaluation\n",
    "\n",
    "# Config (edit if needed)\n",
    "CTX_FILE = \"amazon_help_doc.txt\"\n",
    "MODEL_PATH = r\"C:\\amrita_uni\\Projects\\BeyondChats\\model\"   # <-- your local sentence-transformer path\n",
    "STORAGE_DIR = Path(\"storage\")\n",
    "STORAGE_DIR.mkdir(exist_ok=True)\n",
    "INDEX_PATH = STORAGE_DIR / \"faiss.index\"\n",
    "META_PATH = STORAGE_DIR / \"meta.pkl\"\n",
    "EMB_VEC_PATH = STORAGE_DIR / \"embeddings.npy\"\n",
    "\n",
    "# Ollama invocation\n",
    "OLLAMA_CMD = [\"ollama\", \"run\", \"mistral\"]\n",
    "\n",
    "# Retrieval defaults\n",
    "INDEX_TOP_K = 5\n",
    "SIM_THRESHOLD = 0.20   # starting point; tune on eval data (0.6-0.75 is typical)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d83e306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SentenceTransformer from: C:\\amrita_uni\\Projects\\BeyondChats\\model\n",
      "Loaded 100 context lines.\n",
      "1 If you are on the Amazon homepage and want to search for a specific product like Crocs, move to the large search bar at the top center of the page, ty\n",
      "2 If you are on the homepage and want to track your past orders, hover your mouse over the “Accounts & Lists” option at the top right corner, click on “\n",
      "3 If you are browsing from the homepage and wish to check for discounts and deals, click on the “All” menu at the top left, select “Today’s Deals,” and \n",
      "4 If you are on the homepage and want to redeem a gift card, hover over “Accounts & Lists,” click on “Gift Card Balance,” then select “Redeem a Gift Car\n",
      "5 If you are on the homepage and need to update your payment methods, hover over “Accounts & Lists,” click on “Your Account,” choose “Payment Options,” \n"
     ]
    }
   ],
   "source": [
    "# Cell 2: load embedding model and context\n",
    "print(\"Loading SentenceTransformer from:\", MODEL_PATH)\n",
    "embedder = SentenceTransformer(MODEL_PATH)\n",
    "\n",
    "# Read your context file\n",
    "if not Path(CTX_FILE).exists():\n",
    "    raise FileNotFoundError(f\"Context file {CTX_FILE} not found in project root.\")\n",
    "with open(CTX_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    context_lines = [ln.strip() for ln in f.readlines() if ln.strip()]\n",
    "\n",
    "print(f\"Loaded {len(context_lines)} context lines.\")\n",
    "# Optional: show first few\n",
    "for i, ln in enumerate(context_lines[:5], 1):\n",
    "    print(i, ln[:150])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787ac362",
   "metadata": {},
   "source": [
    "IndexFlatIP — inner product for cosine on normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc4bc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing index, embeddings and metadata.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: create and save FAISS index + metadata + embeddings\n",
    "def build_and_save_index(texts: List[str], embedder: SentenceTransformer,\n",
    "                         index_path: Path = INDEX_PATH, meta_path: Path = META_PATH,\n",
    "                         emb_vec_path: Path = EMB_VEC_PATH):\n",
    "    print(\"Computing embeddings (this may take some time)...\")\n",
    "    embeddings = embedder.encode(texts, convert_to_numpy=True, show_progress_bar=True, batch_size=32)\n",
    "    # Normalize for cosine search with IndexFlatIP\n",
    "    faiss.normalize_L2(embeddings)\n",
    "    dim = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatIP(dim)\n",
    "    index.add(embeddings)\n",
    "    faiss.write_index(index, str(index_path))\n",
    "    print(\"FAISS index saved to\", index_path)\n",
    "    # Save embeddings & metadata\n",
    "    np.save(str(emb_vec_path), embeddings)\n",
    "    print(\"Embeddings saved to\", emb_vec_path)\n",
    "    metadata = [{\"line_no\": i+1, \"text\": t} for i, t in enumerate(texts)]\n",
    "    with open(str(meta_path), \"wb\") as f:\n",
    "        pickle.dump(metadata, f)\n",
    "    print(\"Metadata saved to\", meta_path)\n",
    "    return index, embeddings, metadata\n",
    "\n",
    "if not INDEX_PATH.exists() or not META_PATH.exists() or not EMB_VEC_PATH.exists():\n",
    "    idx, embs, metadata = build_and_save_index(context_lines, embedder)\n",
    "else:\n",
    "    # load\n",
    "    idx = faiss.read_index(str(INDEX_PATH))\n",
    "    embs = np.load(str(EMB_VEC_PATH))\n",
    "    with open(str(META_PATH), \"rb\") as f:\n",
    "        metadata = pickle.load(f)\n",
    "    print(\"Loaded existing index, embeddings and metadata.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "744b874f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([{'idx': 0, 'line_no': 1, 'text': 'If you are on the Amazon homepage and want to search for a specific product like Crocs, move to the large search bar at the top center of the page, type the product name, press Enter, and then scroll through the results while using the filters on the left-hand panel to narrow your choices by size, color, or price.', 'score': 0.6045942306518555}, {'idx': 49, 'line_no': 50, 'text': 'If you are on the homepage and want to review customer service interactions, scroll to the footer, click “Help,” and access past support chats or requests under “Contact History.”', 'score': 0.3660828173160553}, {'idx': 31, 'line_no': 32, 'text': 'If you are on the homepage and want to check magazine subscriptions, type “Magazine Subscriptions” in the search bar and then browse or purchase directly from the results.', 'score': 0.3560046851634979}, {'idx': 42, 'line_no': 43, 'text': 'If you are on the homepage and want to see gift registries, hover over “Accounts & Lists,” click on “Gift Registry,” and manage your wedding, baby, or other registry lists.', 'score': 0.3502120077610016}, {'idx': 15, 'line_no': 16, 'text': 'If you are on the homepage and want to set up subscription items, hover over “Accounts & Lists,” click on “Your Subscribe & Save Items,” and manage or add products that will be automatically delivered to you on a schedule.', 'score': 0.33571600914001465}], False, 0.6045942306518555)\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: retrieval function using FAISS IndexFlatIP and normalized vectors\n",
    "def search_faiss(query: str, top_k: int = INDEX_TOP_K, threshold: float = SIM_THRESHOLD):\n",
    "    \"\"\"\n",
    "    Returns: retrieved: List[dict] with keys (idx, line_no, text, score)\n",
    "             is_ood: bool (True if max_score < threshold)\n",
    "             max_score: float\n",
    "    \"\"\"\n",
    "    query_emb = embedder.encode([query], convert_to_numpy=True)\n",
    "    faiss.normalize_L2(query_emb)\n",
    "    D, I = idx.search(query_emb, top_k)  # D are inner products (cosine if normalized)\n",
    "    scores = D[0].tolist()\n",
    "    ids = I[0].tolist()\n",
    "    retrieved = []\n",
    "    for score, doc_idx in zip(scores, ids):\n",
    "        if doc_idx < 0:\n",
    "            continue\n",
    "        meta = metadata[doc_idx]\n",
    "        retrieved.append({\n",
    "            \"idx\": int(doc_idx),\n",
    "            \"line_no\": int(meta[\"line_no\"]),\n",
    "            \"text\": meta[\"text\"],\n",
    "            \"score\": float(score)\n",
    "        })\n",
    "    max_score = max(scores) if len(scores) > 0 else 0.0\n",
    "    is_ood = max_score < threshold\n",
    "    return retrieved, is_ood, float(max_score)\n",
    "\n",
    "# quick smoke test\n",
    "print(search_faiss(\"Where do I find Crocs from the homepage?\", top_k=5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e9d0a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Ollama runner and prompt builders\n",
    "\n",
    "def run_ollama_mistral(prompt: str, timeout: int = 60) -> str:\n",
    "    \"\"\"\n",
    "    Calls local ollama run mistral with prompt as stdin and returns stdout.\n",
    "    Raises RuntimeError if ollama returns non-zero or times out.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        res = subprocess.run(OLLAMA_CMD, input=prompt, text=True, capture_output=True, encoding='utf-8', timeout=timeout)\n",
    "    except subprocess.TimeoutExpired as e:\n",
    "        raise RuntimeError(f\"ollama timed out: {e}\")\n",
    "    if res.returncode != 0:\n",
    "        # include stderr for debugging\n",
    "        raise RuntimeError(f\"ollama error (code {res.returncode}):\\n{res.stderr}\")\n",
    "    return res.stdout.strip()\n",
    "\n",
    "def build_generation_prompt(query: str, retrieved: List[dict]) -> str:\n",
    "    \"\"\"\n",
    "    Build a strict instruction prompt. We include the top retrieved results (with line numbers).\n",
    "    Must instruct the model to not hallucinate and to give professional, step-by-step directions.\n",
    "    \"\"\"\n",
    "    if not retrieved:\n",
    "        return (f\"User question: {query}\\n\\n\"\n",
    "                \"This question cannot be answered from the provided knowledge base. \"\n",
    "                \"Respond exactly (no extra content): \\\"Sorry, I cannot answer that from the provided document. \"\n",
    "                \"Would you like to contact support?\\\"\")\n",
    "    ctx = \"\\n\".join([f\"[{r['line_no']}] {r['text']}\" for r in retrieved])\n",
    "    prompt = f\"\"\"\n",
    "You are a professional Amazon Help Assistant. You MUST follow these rules:\n",
    "\n",
    "1) Use ONLY the information given in the CONTEXT block below. Do NOT invent or assume facts.\n",
    "2) If the CONTEXT does NOT contain enough information to answer the question, respond EXACTLY with:\n",
    "   \"Sorry, I cannot answer that from the provided document. Would you like to contact support?\"\n",
    "3) Provide step-by-step actionable directions starting from the Amazon homepage.\n",
    "4) If you reference specific instructions, cite the CONTEXT line numbers in square brackets, e.g. [23].\n",
    "5) Be concise, professional, and polite.\n",
    "\n",
    "CONTEXT:\n",
    "{ctx}\n",
    "\n",
    "User Question:\n",
    "{query}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "    return prompt.strip()\n",
    "\n",
    "def build_verification_prompt(query: str, retrieved: List[dict], answer: str) -> str:\n",
    "    \"\"\"\n",
    "    Ask the model to check whether the answer strictly relies only on context.\n",
    "    Request a YES or NO only.\n",
    "    \"\"\"\n",
    "    ctx = \"\\n\".join([f\"[{r['line_no']}] {r['text']}\" for r in retrieved])\n",
    "    verification = f\"\"\"\n",
    "CONTEXT:\n",
    "{ctx}\n",
    "\n",
    "User Question:\n",
    "{query}\n",
    "\n",
    "Proposed Answer:\n",
    "{answer}\n",
    "\n",
    "TASK:\n",
    "Based only on the CONTEXT above, does the Proposed Answer strictly and fully rely ONLY on the provided CONTEXT (without adding any external facts or assumptions)? \n",
    "Answer with a single word: YES or NO.\n",
    "\"\"\"\n",
    "    return verification.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5e192f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: end-to-end RAG answer flow (retrieval -> generate -> verify)\n",
    "FALLBACK_TEXT = \"Sorry, I cannot answer that from the provided document. Would you like to contact support?\"\n",
    "\n",
    "def rag_answer(query: str, top_k: int = INDEX_TOP_K, threshold: float = SIM_THRESHOLD, verify: bool = True) -> Dict:\n",
    "    \"\"\"\n",
    "    Returns a dict: {\n",
    "      'answer': str,\n",
    "      'is_ood': bool,\n",
    "      'max_score': float,\n",
    "      'retrieved': list[ {idx,line_no,text,score} ],\n",
    "      'verified': bool or None  # None if verification not executed\n",
    "    }\n",
    "    \"\"\"\n",
    "    retrieved, is_ood, max_score = search_faiss(query, top_k=top_k, threshold=threshold)\n",
    "    if is_ood:\n",
    "        return {\"answer\": FALLBACK_TEXT, \"is_ood\": True, \"max_score\": max_score, \"retrieved\": retrieved, \"verified\": False}\n",
    "    \n",
    "    # Build prompt and generate\n",
    "    gen_prompt = build_generation_prompt(query, retrieved)\n",
    "    try:\n",
    "        gen_out = run_ollama_mistral(gen_prompt)\n",
    "    except Exception as e:\n",
    "        # If generator fails, return friendly fallback\n",
    "        return {\"answer\": \"Sorry, an internal error occurred while generating an answer.\", \"is_ood\": False, \"max_score\": max_score, \"retrieved\": retrieved, \"verified\": False, \"error\": str(e)}\n",
    "\n",
    "    verified = None\n",
    "    final_answer = gen_out\n",
    "\n",
    "    # Verification pass to detect hallucinations\n",
    "    if verify:\n",
    "        try:\n",
    "            ver_prompt = build_verification_prompt(query, retrieved, gen_out)\n",
    "            ver_out = run_ollama_mistral(ver_prompt)\n",
    "            ver_text = ver_out.strip().upper()\n",
    "            if \"NO\" in ver_text:\n",
    "                final_answer = FALLBACK_TEXT\n",
    "                verified = False\n",
    "            elif \"YES\" in ver_text:\n",
    "                verified = True\n",
    "            else:\n",
    "                # fallback conservative\n",
    "                final_answer = FALLBACK_TEXT\n",
    "                verified = False\n",
    "        except Exception as e:\n",
    "            # if verification fails, be conservative\n",
    "            final_answer = FALLBACK_TEXT\n",
    "            verified = False\n",
    "\n",
    "    return {\"answer\": final_answer, \"is_ood\": False, \"max_score\": max_score, \"retrieved\": retrieved, \"verified\": verified}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c105a764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: How do I track my orders from the Amazon homepage?\n",
      "Answer: To track your orders from the Amazon homepage, follow these steps:\n",
      "\n",
      "1. Hover your mouse over the “Accounts & Lists” option at the top right corner.\n",
      "2. Click on “Your Orders.”\n",
      "3. Review the list of your purchases where each item has an option to track its current delivery status.\n",
      "is_ood: False max_score: 0.7776432633399963 verified: True\n",
      "--------------------------------------------------------------------------------\n",
      "Q: How do I find Crocs from the homepage?\n",
      "Answer: To find Crocs from the Amazon homepage, move to the large search bar at the top center of the page, type \"Crocs\" and press Enter. Then scroll through the results while using the filters on the left-hand panel to narrow your choices by size, color, or price. [1]\n",
      "is_ood: False max_score: 0.6121615767478943 verified: True\n",
      "--------------------------------------------------------------------------------\n",
      "Q: How do I redeem a gift card starting from homepage?\n",
      "Answer: To redeem a gift card starting from the Amazon homepage, follow these steps:\n",
      "\n",
      "1. Hover over \"Accounts & Lists\" located at the top right corner of the page.\n",
      "2. Click on \"Gift Card Balance.\"\n",
      "3. Select \"Redeem a Gift Card.\"\n",
      "4. Carefully enter your gift card claim code before confirming so that the balance is added to your account.\n",
      "is_ood: False max_score: 0.7673120498657227 verified: True\n",
      "--------------------------------------------------------------------------------\n",
      "Q: How do I list a new product as a seller starting from the Amazon homepage?\n",
      "Answer: To list a new product as a seller, starting from the Amazon homepage, follow these steps:\n",
      "\n",
      "1. Go to the top menu and click on \"Seller Central\". [52]\n",
      "2. From the Seller Central landing page, select \"Inventory\" on the top menu.\n",
      "3. Click on \"Add a Product\" in the upper right corner.\n",
      "4. Either match an existing product listing or create a new one with your product details and images.\n",
      "is_ood: False max_score: 0.7337613105773926 verified: True\n",
      "--------------------------------------------------------------------------------\n",
      "Q: Who invented the electric toaster?\n",
      "Answer: Sorry, I cannot answer that from the provided document. Would you like to contact support?\n",
      "is_ood: True max_score: 0.10539291799068451 verified: False\n",
      "--------------------------------------------------------------------------------\n",
      "Q: hello, how are you?\n",
      "Answer: Sorry, I cannot answer that from the provided document. Would you like to contact support?\n",
      "is_ood: True max_score: 0.11822488158941269 verified: False\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: smoke tests\n",
    "tests = [\n",
    "    \"How do I track my orders from the Amazon homepage?\",\n",
    "    \"How do I find Crocs from the homepage?\",\n",
    "    \"How do I redeem a gift card starting from homepage?\",\n",
    "    \"How do I list a new product as a seller starting from the Amazon homepage?\",\n",
    "    \"Who invented the electric toaster?\" , # should be OOD\n",
    "    \"hello, how are you?\" \n",
    "]\n",
    "\n",
    "for q in tests:\n",
    "    out = rag_answer(q)\n",
    "    print(\"Q:\", q)\n",
    "    print(\"Answer:\", out[\"answer\"])\n",
    "    print(\"is_ood:\", out[\"is_ood\"], \"max_score:\", out[\"max_score\"], \"verified:\", out.get(\"verified\"))\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc37b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: keyword 'hello' not found in context; skipping hello, how are you?\n",
      "Eval pairs prepared: 10\n",
      "Retrieval Recall@5: 1.000  MRR@5: 0.950\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Evaluation helpers\n",
    "def find_expected_line_indices(keyword: str) -> List[int]:\n",
    "    \"\"\"Utility: Identifies which context lines are relevant for eval,by key word search and return indices of context_lines containing keyword (case-insensitive).\"\"\"\n",
    "    hits = []\n",
    "    for i, txt in enumerate(context_lines):\n",
    "        if keyword.lower() in txt.lower():\n",
    "            hits.append(i)\n",
    "    return hits\n",
    "\n",
    "def recall_at_k(eval_pairs: List[Tuple[str, List[int]]], k: int = 5) -> float:\n",
    "    \"\"\"iter through all lines in context  check if keyword is present in any of the retrieved lines if yes count as hit\"\"\"\n",
    "    hits = 0\n",
    "    total = len(eval_pairs)\n",
    "    for query, expected_idxs in eval_pairs:\n",
    "        retrieved, _, _ = search_faiss(query, top_k=k, threshold=-1.0)  # threshold disabled for eval\n",
    "        retrieved_idxs = {r[\"idx\"] for r in retrieved}\n",
    "        if any(idx in retrieved_idxs for idx in expected_idxs):\n",
    "            hits += 1\n",
    "    return hits / total\n",
    "\n",
    "def mrr(eval_pairs: List[Tuple[str, List[int]]], k: int = 5) -> float:\n",
    "    \"\"\"Mean Reciprocal Rank: for each query, find rank of first relevant doc, compute mean of 1/rank.\n",
    "    Basically measure how often for each query the first relevant doc appears in top-k.\"\"\"\n",
    "    rr_sum = 0.0\n",
    "    for query, expected_idxs in eval_pairs:\n",
    "        retrieved, _, _ = search_faiss(query, top_k=k, threshold=-1.0)\n",
    "        retrieved_idxs = [r[\"idx\"] for r in retrieved]\n",
    "        rank = None\n",
    "        for i, rid in enumerate(retrieved_idxs, start=1):\n",
    "            if rid in expected_idxs:\n",
    "                rank = i\n",
    "                break\n",
    "        rr_sum += (1.0/rank) if rank else 0.0\n",
    "    return rr_sum / len(eval_pairs)\n",
    "\n",
    "# Build a small eval set by keyword lookup in your context file:\n",
    "eval_queries = [\n",
    "    (\"track my orders\", \"track\"),\n",
    "    (\"search for Crocs\", \"Crocs\"),\n",
    "    (\"redeem gift card\", \"gift card\"),\n",
    "    (\"check prime membership\", \"Prime\"),\n",
    "    (\"return an item\", \"Return or Replace\"),\n",
    "    (\"list a new product\", \"Add a Product\"),\n",
    "    (\"manage inventory\", \"Manage Inventory\"),\n",
    "    (\"create a promotion\", \"Promotions\"),\n",
    "    (\"fulfillment by amazon\", \"Fulfillment by Amazon\"),\n",
    "    (\"contact seller support\", \"Contact Seller\"),\n",
    "    (\"hello, how are you?\", \"hello\")\n",
    "]\n",
    "\n",
    "# Map queries to expected line indices automatically\n",
    "eval_pairs = []\n",
    "for q, keyword in eval_queries:\n",
    "    idxs = find_expected_line_indices(keyword)\n",
    "    if idxs:\n",
    "        eval_pairs.append((q, idxs))\n",
    "    else:\n",
    "        # If keyword not found, skip but print note\n",
    "        print(f\"Warning: keyword '{keyword}' not found in context; skipping {q}\")\n",
    "\n",
    "print(\"Eval pairs prepared:\", len(eval_pairs))\n",
    "\n",
    "# Compute metrics\n",
    "r_at_5 = recall_at_k(eval_pairs, k=5)\n",
    "mrr_5 = mrr(eval_pairs, k=5)\n",
    "print(f\"Retrieval Recall@5: {r_at_5:.3f}  MRR@5: {mrr_5:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ce6b4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation eval (fallback_rate, verified_rate): {'fallback_rate': 0.0, 'verified_rate': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Generation evaluation using verification pass as proxy for faithfulness\n",
    "\n",
    "def evaluate_generation_faithfulness(eval_queries, top_k=5):\n",
    "    total = len(eval_queries)\n",
    "    fallback_count = 0\n",
    "    verified_yes = 0\n",
    "    for q, _ in eval_queries:\n",
    "        out = rag_answer(q, top_k=top_k, verify=True)\n",
    "        if out[\"answer\"].strip() == FALLBACK_TEXT:\n",
    "            fallback_count += 1\n",
    "        if out.get(\"verified\") is True:\n",
    "            verified_yes += 1\n",
    "    fallback_rate = fallback_count / total\n",
    "    verified_rate = verified_yes / total\n",
    "    return {\"fallback_rate\": fallback_rate, \"verified_rate\": verified_rate}\n",
    "\n",
    "g_eval = evaluate_generation_faithfulness([ (q,_) for q,_ in eval_pairs ])\n",
    "print(\"Generation eval (fallback_rate, verified_rate):\", g_eval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3847ba4d",
   "metadata": {},
   "source": [
    "fallback_rate was 0.4 before when threshold was 0.6, since it is now lowered to 0.2 to get better responses for smaller and concise queries we are gettin 0 fallbackrate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
